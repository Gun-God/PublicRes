# 阅读《TEXT2EVENT: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction》：

## 1．创新
提出了TEXT2EVENT统一抽取模型，目的是为了使用单一架构解决不同的信息抽取的任务，核心就是序列到结构网络
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent1.png)

对于每一个事件记录，都包含事件类型、触发器和参数，它们形成了一个类似表的结构。（就像上图中，一个文本通过了神经网络后再经约束和可控生成得到两个表，这两个表每个都包括一个事件类型、一个触发器和三个参数）生成的结构由框架Frame和Schema决定，所以不同的事件类型有不同的结构。

## 2. Text2Event

#### 2.1 事件提取作为结构生成
记录格式到线性化格式的转换过程：
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent2.png)

首先将事件记录表(图a)转换为树的格式(图b)。其中，每个事件类型对应一个子树，将它的参数和事件类型连接起来。红色实线表示event-role关系；蓝色虚线表示label-span关系，其中头部是标签，尾部为文本跨度。转换后的事件树，我们通过深度优先遍历将事件结构编码为线性序列(图c)，其中“（”和“）”是用于表示线性表达式语义结构的结构指示符。相同深度的遍历顺序是在文本中文本跨度（text spans）出现的顺序。(role-作用，span-包括的种类)

#### 2.2 序列到结构网络
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent3.png)
整个任务可以看做是一个文本到结构的生成任务，然后再把结构拍扁成一段文本，也就是将序列结构化表示。这个模型本质上是把T5、BERT直接拿过来用。
给定标记序列x=x1,…,x|x|作为输入，Text2Event首先通过多层转换器编码器计算输入的隐藏向量表示H=h1,…,h|x|：

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent4.png)
其中，每层Encoder(·)都是一个带有多头注意机制的transformer块。在对输入的token序列进行编码后，解码器用顺序输入token的隐藏向量预测输出结构token-by-token。在生成的第i步，自注意解码器预测线性化形式的第i个token yi和解码器状态为：

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent5.png)
其中，每一层Decoder(·)都是一个transformer块，它包含与解码器状态的自注意和与编码器状态H的交叉注意。
生成的输出结构化序列从开始标记开始，以结束标记结束。整个输出序列p(y|x)的条件概率由每一步p(yi | y<i, x)的概率逐步组合：

#### 2.3 约束解码
对于这样一个句子，它可以生成两个事件，但是到底想要生成哪个事件，不能由着它胡乱生成，所以就提出了受限的约束解码。

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent6.png)
抽取结构约束被建模为解码的路径约束，使用Trie树建模
* 约束了解码空间，降低了解码难度
* Schema的约束保证结构和语义上的合法性
* 
#### 2.3 低资源学习
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent7.png)
整个模型第三个核心的组件是低资源学习，也就是使用<Text，Event>对的课程表学习。为了降低学习难度，采用课程表学习，逐步提升生成结构的复杂度。



## 3.实验

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/text2tevent8.png)

左表ACE2005的英文数据上的所有baseline和Text2Event的性能。右表显示了SOTA和Text2Event在ACE05-EN+和ERE-EN上的性能。trigger-C表示触发器的识别和分类。Argument-C表示参数的识别和分类。PLM表示每个模型所使用的预训练语言模型。Text2Event与以上这些模型（还有SOTA）相比，使用监督更少、结构更简单、性能更优。



#### 3.1 迁移学习
Text2Event具有很强的迁移能力。比如说在10个事件类型上做预训练，然后再迁移到剩下23类的事件类别上做抽取。在没有加迁移学习的几种模型在触发器抽取和参数抽取上的结果差不了多少，但是引入了迁移学习一下子就变得不一样了，F值一下子就提升了3.7和3.2。


## 4. 总结
介绍了一种信息抽取新范式：结构生成统一建模，这是一种序列到结构的生成模型。能够直接学习包含知识结构平行语料，统一建模事件抽取的所有子任务。