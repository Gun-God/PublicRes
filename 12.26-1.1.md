# 阅读《HMEAE: Hierarchical Modular Event Argument Extraction》：

## 1．摘要

本文解决的是事件元素抽取（EAE）任务。

现有的方法独立地对每个argument进行分类，忽视了不同argument roles间的概念相关性。本文提出了HMEAE（Hierarchical Modular Event Argument Extraction）模型处理EAE任务。

作者为概念层次（concept hierarchy）的每个基本单元设计了一个神经网络模块，然后使用逻辑操作，将相关的单元模块分层地组成一个面向角色的模块网络（modular network），对特定的argument role进行分类。

由于许多的argument roles共享相同的高层次（high-level）的单元模块，argument roles间的关联就得到了利用，有助于更好地抽取出特定的事件arguments。

实验证明了HMEAE可以有效地利用概念层次的知识，效果优于state-of-the-art baselines。

## 2. 介绍

事件抽取（EE）通常看成由两个子任务构成：事件检测（ED）、事件元素抽取（EAE）。近些年来，EAE成了EE的瓶颈。

EAE的目的是识别出是事件arguments的实体并对该实体在事件中扮演的角色进行分类。
现有的方法都是将元素角色看成是彼此之间相互独立的，忽视了一些元素角色和其他元素的概念相似性。

<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE1.png)
<br>
以上图为例，相比于"Time-within"，“Seller"在概念上和"Buyer"更接近，因为它们共享了相同的上级概念"Person"和"Org”。概念层次可以提供额外的有关元素角色间关联的信息，有助于元素角色的分类。

## 3. 创新点

作者受先前的层次分类网络和神经模块网络（NMNs）的启发，提出了HMEAE模型，利用了概念层次的信息。

HMEAE模型采用了NMNs，模仿概念层次的结构，实现了一种灵活的网络结构，为更好的分类性能提供了有效的归纳偏差（inductive bias）。

作者将概念分为两类：表示抽象概念的上级概念；细粒度的元素角色（argument roles）。一个元素角色可以从属于多个上级概念。

<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE2.png)
<br>
如上所示，为每个概念设置了一个NMN，并将其组成了一个面向角色的模块网络，以预测每个实体的元素角色：

1）首先，对于每个上级概念，有一个上级概念模块（SCM）来突出和概念有关的上下文信息；

2）然后，对于每个元素角色，使用针对特定角色的逻辑模块整合和其相对应的SCMs，以得到统一的高层次的模块；

3）最终，使用元素角色分类器，预测实体是否扮演了给定的元素角色。

本文的模型将概念层次纳入考虑有以下好处：1）高层次的模块可以有效增强分类器性能；2）不同元素角色共享上级概念模块。



### 4 模型
HMEAE模型结构，由3部分组成
* 实例编码器（instance encoder）：将句子编码成隐层嵌入，并使用特征聚合器将句子信息聚合成统一的实例嵌入；
* 分层模块的注意力（hierarchical modular attention component）：生成面向角色的嵌入，以突出参数角色上级概念的信息；
* 元素角色分类器（argument role classifier）：使用实例嵌入和面向角色的嵌入，针对该实例估计出特定元素角色的概率。
#### 4.1 Instance Encoder
##### 句子编码器
将单词序列编码成隐层嵌入：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE3.png)
<br>
其中E(⋅)是一个神经网络，本文使用CNN和BERT作为编码器

##### 特征聚合器
将隐层嵌入聚合成一个实例嵌入。本文使用dynamic multi-pooling作为特征聚合器：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE4.png)
<br>

#### 4.2 Hierarchical Modular Attention
##### 上级概念模块（SCM）

对于特定的上级概念c，使用可训练的向量Uc
表示其语义特征。作者采用了多层感知机（MLP）来计算注意力分值。

首先计算隐层状态：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE5.png)
<br>
然后，进行softmax操作，为每个隐层嵌入hi得到对应的注意力分值：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE6.png)
<br>
其中，Wa,Wb是可训练的矩阵，并且在不同的SCM间共享。
##### Logic Union Module
给定一个元素角色r ∈R，定义它的k个上级概念为C1,C2, ...k，针对hi的相应的注意力分值。
对这些注意力分值求均值，得到面向角色(role-oriented）的注意力分值:
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE7.png)
<br>
然后使用上面计算出的面向角色的注意力分值作为权重，对所有的隐层嵌入进行加权求和，得到面向角色的嵌入：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE8.png)
<br>
#### 4.3 Argument Role Classifier
将实例嵌入x和实例的面向角色的嵌入eF作为分类器的输入，估计给定实例x的条件下，角色r ∈ R的概率。其中，r是元素角色r的嵌入。
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE9.png)
<br>
目标函数定义如下：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE10.png)
<br>
### 5. 实验
数据集 ACE 2005, TAC KBP 2016
在两个数据集上进行实验，不同方法的结果如下：
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE11.png)
<br>
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE12.png)
<br>
从ACE2005数据集中随机采样了一个句子，该句在HMEAE(BERT)模型中的注意力分值s可视化如图所示。可以看出单词隐层嵌入的注意力分值，在与其相关的上级概念上得分较高。这表明，由于上级概念模块（SCM）是共享的，所以无需经过专门数据的训练，SCM就可以很好地捕获概念特征。
<br><br>
![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/HMEAE13.png)
<br>