# 阅读《Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation》：

## 1．介绍
文档级关系抽取(DocRE)问题是信息抽取和自然语言处理研究的一个重要问题。DocRE任务旨在提取文档中多个实体之间的关系。DocRE任务在以下几个方面比句子级任务更具挑战性:(1)DocRE任务的复杂性随实体数量的增加呈二次曲线增长。如果一个文档包含n个实体，则必须对n(n - 1)个实体对进行分类决策，且大多数实体对不包含任何关系。(2)除了正例和负例的不平衡外，正例对关系类型的分布也非常不平衡。以DocRED数据集为例，共有96种关系类型，其中前10种关系占所有关系标签的59.4%。这种不平衡显著增加了文档级RE任务的难度。

## 2.现有难点
1. 现存的方法关注实体对的句法特征，而忽略了实体对之间的交互作用。 Zhang et al. (2021) and Li et al. (2021)已经使用CNN结构对实体对之间的交互进行编码，但是CNN结构不能捕获two-hop推理路径内的所有元素。
2. 目前还没有工作可以直接的解决类的不平衡问题。现存的工作仅仅关注阈值学习来平衡正例和负例，但正例内部的类不平衡问题并没有得到解决。 
3. 最后，关于将远程监督数据应用于DocRE任务的研究很少。Xu等人(2021)已经表明，远程监督数据能够提高文档级关系提取的性能。然而，它只是单纯地使用远监督数据对正则模型进行预训练。

## 3. 创新
* 提出使用一个axial attention模块作为特征抽取器去提升two-hop()关系的推理能力。
* 提出自适应焦点损失来解决标签分配不平衡的问题。提出的损失函数鼓励long-tail(不均衡)类在总的损失中占比较多。
* 使用知识蒸馏来克服标注数据和远程监督数据之间的差异。具体来说就是使用少量的注释数据训练教师模型。然后用教师数据对大量远程监督数据进行预测，然后生成的预测作为软标签来训练学生网络。最后，再使用人工标注的数据来调整学生模型。



## 4. 方法

#### 4.1 模型架构

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/damo1.png)

有三个部分：1. 特征表示学习，2. 适应性焦距损失， 3. 知识蒸馏

* 我们首先用一个预训练的语言模型来提取实体对的上下文表示，然后这个表示会被轴向注意力模组增强，它能够编码实体对之间的相关性
* 然后我们用一个前馈神经网络分类器来得到 logits 并计算它们的损失。用适应性焦距损失来更好地从长尾分布的类别中学习
  （logits一般指未归一化的概率，即softmax层的输入)
* 我们用标注数据来训练一个教师模型，并用它的输出作为软标签。然后我们用这些软标签和远程标签来预训练一个学生模型，这个学生模型最后被标注数据微调。

首先将事件记录表(图a)转换为树的格式(图b)。其中，每个事件类型对应一个子树，将它的参数和事件类型连接起来。红色实线表示event-role关系；蓝色虚线表示label-span关系，其中头部是标签，尾部为文本跨度。转换后的事件树，我们通过深度优先遍历将事件结构编码为线性序列(图c)，其中“（”和“）”是用于表示线性表达式语义结构的结构指示符。相同深度的遍历顺序是在文本中文本跨度（text spans）出现的顺序。(role-作用，span-包括的种类)

#### 4.2 特征表示学习
实体表示
我们用一个预训练语言模型作为编码器。对于一个长度为l的文本D是在位置t处的单词，依据一些先验工作，我们用特殊的记号来标记实体，在实体的mention的开始位置和结束位置会有一个特殊的记号’*'。然后我们用预训练的语言模型来得到这个文本的contextualized embeddings H。

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/damo2.png)


实体对表示

仿效 Zhou 的做法，使用了分组的双线性函数做特征组合。实体的嵌入表示先被分成 k 个同等大小的组，实体对表示g由以下公式得到：

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/damo3.png)

#### 4.3 适应性焦距损失 (Adaptive Focal Loss)
轴向注意力模块之上还有一个MLP，经过它会得到对所有关系的 logit，公式如下:

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/damo4.png)
对于一般的多标签分类问题来说，一般会使用 binary cross-entropy 损失函数。不过这个问题需要一个全局概率阈值，来推断实体对间是否存在关系。

## 5. 实验

数据集使用DocRED和HacRED

![模型在时空复杂度上的比较](https://raw.githubusercontent.com/Gun-God/PublicRes/main/img/damo5.png)

#### 5.1 实验结果
知识蒸馏能够大幅提升作者的模型。不使用知识蒸馏，也能得到不错的效果。模型在HacRED上的效果要比DocRED上的效果高很多，有两个可能的因素：
* HacRED的标注训练样本比DocRED多很多
* HacRED的关系类型分布要更均匀


#### 5.2 消融实验
首先把标签分为两个子集，第一个子集包含了最多的十个标签，占正标签的 59.4%，第二个自己包含了剩下的86个标签，将AFL更换为ATL，观察AFL的效果。实验发现更换为ATL之后，总性能的F1分数下降，且在长尾标签上的下降值要比在总标签和频繁标签上的下降值更大，说明AFL确实起到了效果。轴向注意力模块也对长尾标签更有利。
然后检验轴向注意力模块，作者还比较了 Zeng et al利用多跳关系的方法，实验结果说明轴向注意力模块有效且利用多跳注意力关系的方法更好。

